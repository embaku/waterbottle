{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtvu2gccHNjS",
        "outputId": "21f78dd7-734b-4e22-c53a-5e2b493768df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp310-cp310-linux_x86_64.whl size=3365683 sha256=174e4bcfe406fffffe7edcd245a56bfbdfb4b1d4e92be630cdb352655c432ae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/b5/97ec4cfccdde26e0f3590ad6e09a5242d508dff09704ef86c1\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nKF79g7GSkD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "Vrn5A4_oGjY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8054f7-0808-4396-e286-1fa424ac3c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  mpi4py import MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()"
      ],
      "metadata": {
        "id": "J9UdKKiTG2VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, x_train, y_train, rank, size):\n",
        "# Split the data across the nodes\n",
        "    n = len(x_train)\n",
        "    chunk_size = n // size\n",
        "    start = rank * chunk_size \n",
        "    end = (rank + 1) * chunk_size\n",
        "    if rank == size - 1:\n",
        "        end = n\n",
        "    x_train_chunk = x_train[start:end]\n",
        "    y_train_chunk = y_train[start:end]\n",
        "    model.compile(optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "    #Train the model\n",
        "    model.fit(x_train_chunk, y_train_chunk, epochs=1, batch_size=32)\n",
        "    # Compute the accuracy on the training data\n",
        "    train_loss, train_acc = model.evaluate(x_train_chunk, y_train_chunk, verbose=2)\n",
        "    # Reduce the accuracy across all nodes\n",
        "    train_acc = comm.allreduce(train_acc, op=MPI.SUM)\n",
        "    return train_acc / size"
      ],
      "metadata": {
        "id": "ZEZl6LW0G41z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "# Train the model\n",
        "    train_acc = train(model, x_train, y_train, rank, size)\n",
        "    # Compute the accuracy on the test data\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "    # Reduce the accuracy across all nodes\n",
        "    test_acc = comm.allreduce(test_acc, op=MPI.SUM)\n",
        "    # Print the results \n",
        "    if rank ==0:\n",
        "        print(f\"Epoch {epoch + 1}: Train accuracy = {train_acc:.4f}, Test accuracy = {test_acc /size:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87yFwFXNHkRb",
        "outputId": "bdc5f0f8-b2e0-482d-e29d-09892b8ba8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 39s 20ms/step - loss: 0.2040 - accuracy: 0.9419\n",
            "1875/1875 - 11s - loss: 0.0772 - accuracy: 0.9785 - 11s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0779 - accuracy: 0.9762 - 2s/epoch - 6ms/step\n",
            "Epoch 1: Train accuracy = 0.9785, Test accuracy = 0.9762\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0752 - accuracy: 0.9780\n",
            "1875/1875 - 11s - loss: 0.0563 - accuracy: 0.9837 - 11s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0641 - accuracy: 0.9783 - 2s/epoch - 6ms/step\n",
            "Epoch 2: Train accuracy = 0.9837, Test accuracy = 0.9783\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0574 - accuracy: 0.9829\n",
            "1875/1875 - 11s - loss: 0.0442 - accuracy: 0.9873 - 11s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0578 - accuracy: 0.9807 - 2s/epoch - 6ms/step\n",
            "Epoch 3: Train accuracy = 0.9873, Test accuracy = 0.9807\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0469 - accuracy: 0.9866\n",
            "1875/1875 - 10s - loss: 0.0365 - accuracy: 0.9891 - 10s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0564 - accuracy: 0.9813 - 2s/epoch - 5ms/step\n",
            "Epoch 4: Train accuracy = 0.9891, Test accuracy = 0.9813\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0402 - accuracy: 0.9880\n",
            "1875/1875 - 11s - loss: 0.0294 - accuracy: 0.9917 - 11s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0521 - accuracy: 0.9827 - 2s/epoch - 6ms/step\n",
            "Epoch 5: Train accuracy = 0.9917, Test accuracy = 0.9827\n"
          ]
        }
      ]
    }
  ]
}